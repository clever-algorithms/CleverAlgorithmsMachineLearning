% This file was created with JabRef 2.7.2.
% Encoding: UTF-8

@ARTICLE{Breiman2001,
  author = {Leo Breiman},
  title = {Random Forests},
  journal = {Machine Learning},
  year = {2001},
  volume = {45},
  pages = {5--32},
  number = {1},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee = {http://dx.doi.org/10.1023/A:1010933404324}
}

@ARTICLE{Breiman1996,
  author = {Breiman, Leo},
  title = {Bagging predictors},
  journal = {Mach. Learn.},
  year = {1996},
  volume = {24},
  pages = {123--140},
  month = {August},
  acmid = {231989},
  address = {Hingham, MA, USA},
  doi = {10.1023/A:1018054314350},
  issn = {0885-6125},
  issue = {2},
  keywords = {aggregation, averaging, bootstrap, combining},
  numpages = {18},
  publisher = {Kluwer Academic Publishers},
  url = {http://dl.acm.org/citation.cfm?id=231986.231989}
}

@BOOK{Breiman1984,
  title = {Classification and regression trees},
  publisher = {Chapman and Hall},
  year = {1984},
  author = {Breiman, Leo and Friedman, J. H. and Olshen, R. A. and Stone, C.
	J.},
  owner = {brownlee},
  timestamp = {2011.11.23}
}

@INPROCEEDINGS{Dietterich2000,
  author = {Dietterich, Thomas G.},
  title = {Ensemble Methods in Machine Learning},
  booktitle = {Proceedings of the First International Workshop on Multiple Classifier
	Systems},
  year = {2000},
  series = {MCS '00},
  pages = {1--15},
  address = {London, UK},
  publisher = {Springer-Verlag},
  acmid = {743935},
  isbn = {3-540-67704-6},
  numpages = {15},
  url = {http://dl.acm.org/citation.cfm?id=648054.743935}
}

@TECHREPORT{Dietterich1995,
  author = {Dietterich, T. G., and Kong, E. B.},
  title = {Machine Learning Bias, Statistical Bias, and Statistical Variance
	of Decision Tree Algorithms},
  institution = {Department of Computer Science, Oregon State University},
  year = {1995},
  address = {Corvallis, Oregon},
  owner = {brownlee},
  timestamp = {2011.11.24}
}

@ARTICLE{Freund1997,
  author = {Yoav Freund and Robert E. Schapire},
  title = {A Decision--Theoretic Generalization of On--Line Learning and an
	Application to Boosting},
  journal = {Journal of Computer and System Sciences},
  year = {1997},
  volume = {55},
  pages = {119--139},
  number = {1},
  doi = {10.1006/jcss.1997.1504},
  issn = {0022-0000},
  url = {http://www.sciencedirect.com/science/article/pii/S002200009791504X}
}

@ARTICLE{Friedman2001,
  author = {Friedman, Jerome H.},
  title = {{Greedy function approximation: A gradient boosting machine}},
  journal = {Annals of Statistics},
  year = {2001},
  volume = {29},
  pages = {1189--1232},
  abstract = {{Function approximation is viewed from the perspective of numerical
	optimization in function space, rather than parameter space. A connection
	is made between stagewise additive expansions and steepest--descent
	minimization. A general gradient--descent \&amp;quot;boosting\&amp;quot;
	paradigm is developed for additive expansions based on any fitting
	criterion. Specific algorithms are presented for least--squares,
	least--absolute--deviation, and Huber--M loss functions for regression,
	and multi--class logistic likelihood for classification. Special
	enhancements are derived for the particular case where the individual
	additive components are decision trees, and tools for interpreting
	such \&amp;quot;TreeBoost \&amp;quot; models are presented. Gradient
	boosting of decision trees produces competitive, highly robust, interpretable
	procedures for regression and classification, especially appropriate
	for mining less than clean data. Connections between this approach
	and the boosting methods of Freund and Shapire 1996, and Friedman,
	Hastie, and Tibshirani 1998 are discussed.}},
  citeulike-article-id = {3154111},
  citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.869},
  posted-at = {2008-08-25 20:40:24},
  priority = {2},
  url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.31.869}
}

@ARTICLE{Hocking1976,
  author = {Hocking, R R},
  title = {The Analysis and Selection of Variables in Linear Regression},
  journal = {Biometrics},
  year = {1976},
  volume = {32},
  pages = {1--49},
  number = {1},
  url = {http://www.jstor.org/stable/2529336}
}

@BOOK{Hosmer2000,
  title = {Applied logistic regression},
  publisher = {Wiley},
  year = {2000},
  author = {Hosmer, D.W. and Lemeshow, S.},
  series = {Wiley series in probability and statistics: Texts and references
	section},
  isbn = {9780471356325},
  lccn = {00036843},
  url = {http://books.google.com.au/books?id=DEtar8K5ASsC}
}

@BOOK{Kleinbaum2010,
  title = {Logistic Regression: A Self-Learning Text},
  publisher = {Springer},
  year = {2010},
  author = {Kleinbaum, D.G. and Klein, M. and Pryor, E.R.},
  series = {Statistics for Biology and Health},
  isbn = {9781441917416},
  lccn = {2009943538},
  url = {http://books.google.com.au/books?id=J7E0JQweHkoC}
}

@TECHREPORT{Komarek2005,
  author = {Paul Komarek and Andrew Moore},
  title = {Making Logistic Regression A Core Data Mining Tool: A Practical Investigation
	of Accuracy, Speed, and Simplicity},
  institution = {Robotics Institute, Carnegie Mellon University},
  year = {2005},
  number = {CMU-RI-TR-05-27},
  address = {Pittsburgh, PA},
  month = {May},
  howpublished = {technical report},
  pages = {13},
  volume = {TR-05-27}
}

@ARTICLE{Lagarias1998,
  author = {Lagarias, Jeffrey C. and Reeds, James A. and Wright, Margaret H.
	and Wright, Paul E.},
  title = {Convergence Properties of the Nelder--Mead Simplex Method in Low
	Dimensions},
  journal = {SIAM J. on Optimization},
  year = {1998},
  volume = {9},
  pages = {112--147},
  month = {May},
  acmid = {589108},
  address = {Philadelphia, PA, USA},
  doi = {http://dx.doi.org/10.1137/S1052623496303470},
  issn = {1052-6234},
  issue = {1},
  keywords = {Nelder--Mead simplex methods, direct search methods, nonderivative
	optimization},
  numpages = {36},
  publisher = {Society for Industrial and Applied Mathematics},
  url = {http://dx.doi.org/10.1137/S1052623496303470}
}

@ARTICLE{Mundry2009,
  author = {Mundry, Roger and Nunn, Charles L},
  title = {Stepwise model fitting and statistical inference: turning noise into
	signal pollution.},
  journal = {The American naturalist},
  year = {2009},
  volume = {173},
  pages = {119--23},
  number = {1},
  publisher = {UChicago Press},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/19049440}
}

@ARTICLE{Nelder1965,
  author = {Nelder, J. A. and Mead, R.},
  title = {{A Simplex Method for Function Minimization}},
  journal = {The Computer Journal},
  year = {1965},
  volume = {7},
  pages = {308--313},
  number = {4},
  month = jan,
  abstract = {{A method is described for the minimization of a function of n variables,
	which depends on the comparison of function values at the (n + 1)
	vertices of a general simplex, followed by the replacement of the
	vertex with the highest value by another point. The simplex adapts
	itself to the local landscape, and contracts on to the final minimum.
	The method is shown to be effective and computationally compact.
	A procedure is given for the estimation of the Hessian matrix in
	the neighbourhood of the minimum, needed in statistical estimation
	problems.}},
  citeulike-article-id = {3009487},
  citeulike-linkout-0 = {http://dx.doi.org/10.1093/comjnl/7.4.308},
  citeulike-linkout-1 = {http://comjnl.oxfordjournals.org/content/7/4/308.abstract},
  citeulike-linkout-2 = {http://comjnl.oxfordjournals.org/content/7/4/308.full.pdf},
  citeulike-linkout-3 = {http://comjnl.oxfordjournals.org/cgi/content/abstract/7/4/308},
  day = {1},
  doi = {10.1093/comjnl/7.4.308},
  posted-at = {2008-09-15 16:23:09},
  priority = {2},
  url = {http://dx.doi.org/10.1093/comjnl/7.4.308}
}

@BOOK{Pampel2000,
  title = {Logistic regression: a primer},
  publisher = {Sage Publications},
  year = {2000},
  author = {Pampel, F.C.},
  series = {Sage university papers series: Quantitative applications in the social
	sciences},
  isbn = {9780761920106},
  lccn = {00008060},
  url = {http://books.google.com.au/books?id=lfzSqxFceq0C}
}

@ARTICLE{Peduzzi1996,
  author = {Peduzzi, Peter and Concato, John and Kemper, Elizabeth and Holford,
	Theodore R. and Feinstein, Alvan R.},
  title = {{A simulation study of the number of events per variable in logistic
	regression analysis}},
  journal = {Journal of Clinical Epidemiology},
  year = {1996},
  volume = {49},
  pages = {1373--1379},
  number = {12},
  month = dec,
  abstract = {{We performed a Monte Carlo study to evaluate the effect of the number
	of events per variable (EPV) analyzed in logistic regression analysis.
	The simulations were based on data from a cardiac trial of 673 patients
	in which 252 deaths occurred and seven variables were cogent predictors
	of mortality; the number of events per predictive variable was ()
	for the full sample. For the simulations, at values of EPV = 2, 5,
	10, 15, 20, and 25, we randomly generated 500 samples of the 673
	patients, chosen with replacement, according to a logistic model
	derived from the full sample. Simulation results for the regression
	coefficients for each variable in each group of 500 samples were
	compared for bias, precision, and significance testing against the
	results of the model fitted to the original sample. For EPV values
	of 10 or greater, no major problems occurred. For EPV values less
	than 10, however, the regression coefficients were biased in both
	positive and negative directions; the large sample variance estimates
	from the logistic model both overestimated and underestimated the
	sample variance of the regression coeffi-cients; the 90\% confidence
	limits about the estimated values did not have proper coverage; the
	Wald statistic was conservative under the null hypothesis; and paradoxical
	associations (significance in the wrong direction) were increased.
	Although other factors (such as the total number of events, or sample
	size) may influence the validity of the logistic model, our findings
	indicate that low EPV can lead to major problems.}},
  citeulike-article-id = {2305744},
  citeulike-linkout-0 = {http://dx.doi.org/10.1016/S0895-4356(96)00236-3},
  citeulike-linkout-1 = {http://linkinghub.elsevier.com/retrieve/pii/S0895-4356(96)00236-3},
  citeulike-linkout-2 = {http://www.sciencedirect.com/science/article/B6T84-3W30X5C-8/2/f1b4e237713e6d272e85c988556f1d4e},
  doi = {10.1016/S0895-4356(96)00236-3},
  issn = {08954356},
  keywords = {logistic, model\_selection, power},
  posted-at = {2011-03-24 19:17:32},
  priority = {2},
  url = {http://dx.doi.org/10.1016/S0895-4356(96)00236-3}
}

@BOOK{Quinlan1993,
  title = {C4.5: Programs for Machine Learning},
  publisher = {Morgan Kaufmann},
  year = {1993},
  author = {J. R. Quinlan},
  owner = {brownlee},
  timestamp = {2011.11.23}
}

@MANUAL{RDevelopmentCoreTeam2011,
  title = {R: A Language and Environment for Statistical Computing},
  author = {{R Development Core Team}},
  organization = {R Foundation for Statistical Computing},
  address = {Vienna, Austria},
  year = {2011},
  note = {{ISBN} 3-900051-07-0},
  url = {http://www.R-project.org}
}

@TECHREPORT{Shewchuk1994,
  author = {Shewchuk, Jonathan R.},
  title = {{An Introduction to the Conjugate Gradient Method Without the Agonizing
	Pain}},
  year = {1994},
  address = {Pittsburgh, PA, USA},
  citeulike-article-id = {264342},
  citeulike-linkout-0 = {http://www.cs.cmu.edu/\~{}quake-papers/painless-conjugate-gradient.pdf},
  citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=865018},
  keywords = {optimization},
  posted-at = {2007-10-09 14:30:47},
  priority = {2},
  publisher = {Carnegie Mellon University},
  url = {http://www.cs.cmu.edu/\~{}quake-papers/painless-conjugate-gradient.pdf}
}

@ARTICLE{Spendley1962,
  author = {Spendley, W. and Hext, G. R. and Himsworth, F. R.},
  title = {{Sequential Application of Simplex Designs in Optimization and Evolutionary
	Operation}},
  journal = {Technometrics},
  year = {1962},
  volume = {4},
  pages = {441--461},
  citeulike-article-id = {2846890},
  keywords = {dfo, optimisation, simplex},
  posted-at = {2008-05-30 10:37:13},
  priority = {2}
}

@ARTICLE{Tibshirani1996,
  author = {Tibshirani, Robert},
  title = {{Regression shrinkage and selection via the lasso}},
  journal = {J. Roy. Statist. Soc. Ser. B},
  year = {1996},
  volume = {58},
  pages = {267--288},
  number = {1},
  abstract = {{We propose a new method for estimation in linear models. The \&quot;lasso\&quot;
	minimizes the residual sum of squares subject to the sum of the absolute
	value of the coefficients being less than a constant. Because of
	the nature of this constraint it tends to produce some coefficients
	that are exactly zero and hence gives interpretable models. Our simulation
	studies suggest that the lasso enjoys some of the favourable properties
	of both subset selection and ridge regression. It produces interpretable
	models like subset selection and exhibits the stability of ridge
	regression. There is also an interesting relationship with recent
	work in adaptive function estimation by Donoho and Johnstone. The
	lasso idea is quite general and can be applied in a variety of statistical
	models: extensions to generalized regression models}},
  citeulike-article-id = {416068},
  citeulike-linkout-0 = {http://www.ams.org/mathscinet-getitem?mr=1379242},
  keywords = {feature-selection, lasso, regression, ridge-regression, shrinkage},
  mrnumber = {MR1379242},
  posted-at = {2008-11-13 17:23:13},
  priority = {3},
  url = {http://www.ams.org/mathscinet-getitem?mr=1379242}
}

@TECHREPORT{Tibshirani1996a,
  author = {Tibshirani, R.},
  title = {{Bias, Variance, and Prediction Error for Classification Rules}},
  institution = {Department of Statistics, University of Toronto},
  year = {1996},
  citeulike-article-id = {340511},
  keywords = {biasvariance, diplomarbeit},
  posted-at = {2005-10-04 12:14:09},
  priority = {0}
}

@BOOK{Walters1991,
  title = {Sequential simplex optimization: a technique for improving quality
	and productivity in research, development, and manufacturing},
  publisher = {CRC Press},
  year = {1991},
  author = {Walters, F.H.},
  series = {Chemometrics series},
  isbn = {9780849358944},
  lccn = {91014187},
  url = {http://books.google.com.au/books?id=hpxTAAAAMAAJ}
}

@ARTICLE{Whittingham2006,
  author = {Whittingham, Mark J. and Stephens, Philip A. and Bradbury, Richard
	B. and Freckleton, Robert P.},
  title = {{Why do we still use stepwise modelling in ecology and behaviour?}},
  journal = {Journal of Animal Ecology},
  year = {2006},
  volume = {75},
  pages = {1182--1189},
  number = {5},
  month = sep,
  abstract = {{Summary * 1The biases and shortcomings of stepwise multiple regression
	are well established within the statistical literature. However,
	an examination of papers published in 2004 by three leading ecological
	and behavioural journals suggested that the use of this technique
	remains widespread: of 65 papers in which a multiple regression approach
	was used, 57\% of studies used a stepwise procedure. * 2The principal
	drawbacks of stepwise multiple regression include bias in parameter
	estimation, inconsistencies among model selection algorithms, an
	inherent (but often overlooked) problem of multiple hypothesis testing,
	and an inappropriate focus or reliance on a single best model. We
	discuss each of these issues with examples. * 3We use a worked example
	of data on yellowhammer distribution collected over 4Â years to highlight
	the pitfalls of stepwise regression. We show that stepwise regression
	allows models containing significant predictors to be obtained from
	each year's data. In spite of the significance of the selected models,
	they vary substantially between years and suggest patterns that are
	at odds with those determined by analysing the full, 4-year data
	set. * 4An information theoretic (IT) analysis of the yellowhammer
	data set illustrates why the varying outcomes of stepwise analyses
	arise. In particular, the IT approach identifies large numbers of
	competing models that could describe the data equally well, showing
	that no one model should be relied upon for inference.}},
  address = {Department of Mathematics, University of Bristol, University Walk,
	Bristol, BS8 1TW, UK; ; Royal Society for the Protection of Birds,
	The Lodge, Sandy, Bedfordshire, SG19 2DL, UK; and ; Department of
	Animal and Plant Sciences, University of Sheffield, Sheffield S10
	2TN, UK},
  citeulike-article-id = {786972},
  citeulike-linkout-0 = {http://www.blackwell-synergy.com/doi/abs/10.1111/j.1365-2656.2006.01141.x},
  citeulike-linkout-1 = {http://dx.doi.org/10.1111/j.1365-2656.2006.01141.x},
  citeulike-linkout-2 = {http://www.ingentaconnect.com/content/bsc/janim/2006/00000075/00000005/art00016},
  citeulike-linkout-3 = {http://view.ncbi.nlm.nih.gov/pubmed/16922854},
  citeulike-linkout-4 = {http://www.hubmed.org/display.cgi?uids=16922854},
  citeulike-linkout-5 = {http://www3.interscience.wiley.com/cgi-bin/abstract/118727122/ABSTRACT},
  doi = {10.1111/j.1365-2656.2006.01141.x},
  issn = {0021-8790},
  keywords = {plant\_ecology, statistics},
  pmid = {16922854},
  posted-at = {2009-03-23 10:12:31},
  priority = {2},
  publisher = {Blackwell Publishing Ltd},
  url = {http://dx.doi.org/10.1111/j.1365-2656.2006.01141.x}
}

